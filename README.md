Рекурсивный обход сайта с лимитом в 30.000 конечных ссылок на скачивание дистрибутивов. 
Промежуточные ссылки не нужны. 
Cкачать и распаковать с помощью 7 zip архивы. 
Сформировать по распакованным файлам список “архив – файл – тип - размер”.
Результаты будут находиться в `crawler/bin/`.


How to start
```
 docker run --rm --name my-crawler -v /home/crawler/bin:/app/bin -it crawler:0.1.0 crawl
```
